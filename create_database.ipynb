{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5cb5e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "from sqlite3 import Error\n",
    "\n",
    "# paths to files\n",
    "directory_with_files = '../data'\n",
    "db_name = './dbl.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26a7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_through_files(directory_with_files, db_name):\n",
    "    conn = create_connection(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    for n, filename in enumerate(os.listdir(directory_with_files)):\n",
    "        f = os.path.join(directory_with_files, filename)\n",
    "        if os.path.isfile(f):\n",
    "            write_json_to_db(f, cursor)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "        \n",
    "def write_json_to_db(file, cursor):\n",
    "    data=[]\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for n, line in enumerate(f):\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except ValueError:\n",
    "                print(n, line)\n",
    "            \n",
    "    parse_data(data, cursor)\n",
    "\n",
    "def insert(where, data, cursor):\n",
    "    values_placeholder = \", \".join([\"?\"] * len(data))\n",
    "    into_placeholder = tuple(data.keys())\n",
    "    variables = tuple(data.values())\n",
    "    query = f\"\"\"\n",
    "    INSERT OR IGNORE INTO {where} {into_placeholder}\n",
    "    VALUES ({values_placeholder})\n",
    "    \"\"\"\n",
    "    cursor.execute(query, variables)\n",
    "\n",
    "\n",
    "def tweet_classification(data):\n",
    "    keys=data.keys()\n",
    "    check_for_none=True\n",
    "    if 'in_reply_to_status_id' in keys:\n",
    "        if data['in_reply_to_status_id']!= None:\n",
    "            return reply_processing(data)\n",
    "    if 'retweeted_status' in keys:\n",
    "        return retweet_processing(data)\n",
    "    if 'quoted_status' in keys:\n",
    "        return quote_processing(data)\n",
    "    if 'delete' in keys:\n",
    "        return delete_processing(data)\n",
    "    return original_processing(data)\n",
    "\n",
    "def original_processing(data):\n",
    "    base_data = base_retrieving(data)\n",
    "    text_data = text_retrieving(data)\n",
    "    geo_data = geo_retrieving(data)\n",
    "    tweet_data, entities = base_processing(text_data, base_data)\n",
    "    tweet_data['tweet_type'] = 'original'\n",
    "    return tweet_data, entities, geo_data, None\n",
    "\n",
    "def quote_processing(data):\n",
    "    special ={}\n",
    "    base_data = base_retrieving(data)\n",
    "    text_data = text_retrieving(data)\n",
    "    geo_data = geo_retrieving(data)\n",
    "    tweet_data, entities = base_processing(text_data, base_data)\n",
    "    tweet_data['tweet_type'] = 'quote'\n",
    "    special['quote_id'] = base_data['tweet_id']    \n",
    "    special['quote_of_status_id'] = data['quoted_status_id']\n",
    "    return tweet_data, entities, geo_data, special\n",
    "\n",
    "def retweet_processing(data):\n",
    "    special ={}    \n",
    "    base_data = base_retrieving(data)\n",
    "    text_data = text_retrieving(data['retweeted_status'])\n",
    "    geo_data = geo_retrieving(data)\n",
    "    tweet_data, entities = base_processing(text_data, base_data)\n",
    "    tweet_data['tweet_type'] = 'retweet'\n",
    "    special['retweet_id'] = base_data['tweet_id']\n",
    "    special['retweet_of_status_id'] = data['retweeted_status']['id']\n",
    "    return tweet_data, entities, geo_data, special\n",
    "\n",
    "def reply_processing(data):\n",
    "    special ={}   \n",
    "    base_data = base_retrieving(data)\n",
    "    text_data = text_retrieving(data)\n",
    "    geo_data = geo_retrieving(data)\n",
    "    tweet_data, entities = base_processing(text_data, base_data)\n",
    "    tweet_data['tweet_type'] = 'reply'\n",
    "    special['reply_id'] = base_data['tweet_id']\n",
    "    special['reply_to_user_id'] = data['in_reply_to_user_id']\n",
    "    special['reply_to_status_id'] = data['in_reply_to_status_id']\n",
    "    return tweet_data, entities, geo_data, special\n",
    "\n",
    "\n",
    "def base_processing(text_data, base_data):\n",
    "    tweet_data ={}\n",
    "    entities = {}\n",
    "    tweet_data['tweet_id'] = base_data['tweet_id']\n",
    "    tweet_data['user_id'] = base_data['user_id']\n",
    "    tweet_data['timestamp_ms'] = base_data['timestamp_ms']\n",
    "    tweet_data['text'] = text_data['text']\n",
    "    tweet_data['lang'] = base_data['lang']\n",
    "    entities['hashtags'] = text_data['hashtags']\n",
    "    entities['user_mentions'] = text_data['user_mentions']\n",
    "    entities['symbols'] = text_data['symbols']\n",
    "    return tweet_data, entities\n",
    "    \n",
    "def delete_processing(data):\n",
    "    return 'delete', 'delete', 'delete', 'delete'\n",
    "\n",
    "def text_retrieving(data):\n",
    "    keys = data.keys()\n",
    "    text_data ={}\n",
    "    if 'extended_tweet' in keys:\n",
    "        text_data['text'] = data['extended_tweet']['full_text']\n",
    "        \n",
    "        raw_hashtags = data['extended_tweet']['entities']['hashtags']\n",
    "        hashtags=[]\n",
    "        for hashtag in raw_hashtags:\n",
    "            hashtags.append(hashtag['text'])\n",
    "        text_data['hashtags'] = hashtags\n",
    "        \n",
    "        raw_user_mentions = data['extended_tweet']['entities']['user_mentions']\n",
    "        user_mentions = []\n",
    "        for user_mention in raw_user_mentions:\n",
    "            user_mentions.append(user_mention['id'])\n",
    "        text_data['user_mentions'] = user_mentions\n",
    "        \n",
    "        raw_symbols = data['extended_tweet']['entities']['symbols']\n",
    "        symbols = []\n",
    "        for symbol in raw_symbols:\n",
    "            symbols.append(symbol['text'])\n",
    "        text_data['symbols'] = symbols\n",
    "    else:\n",
    "        text_data['text'] = data['text']\n",
    "        \n",
    "        raw_hashtags = data['entities']['hashtags']\n",
    "        hashtags=[]\n",
    "        for hashtag in raw_hashtags:\n",
    "            hashtags.append(hashtag['text'])\n",
    "        text_data['hashtags'] = hashtags\n",
    "        \n",
    "        raw_user_mentions = data['entities']['user_mentions']\n",
    "        user_mentions = []\n",
    "        for user_mention in raw_user_mentions:\n",
    "            user_mentions.append(user_mention['id'])\n",
    "        text_data['user_mentions'] = user_mentions\n",
    "        \n",
    "        raw_symbols = data['entities']['symbols']\n",
    "        symbols = []\n",
    "        for symbol in raw_symbols:\n",
    "            symbols.append(symbol['text'])\n",
    "        text_data['symbols'] = symbols\n",
    "    text_data['user_id'] = data['user']['id']\n",
    "    return text_data\n",
    "\n",
    "def base_retrieving(data):\n",
    "    keys = data.keys()\n",
    "    return_data={}\n",
    "    \n",
    "    return_data['timestamp_ms'] = data['timestamp_ms']\n",
    "    return_data['tweet_id'] = data['id']\n",
    "    return_data['user_id'] = data['user']['id']\n",
    "    return_data['lang'] = data['lang']\n",
    "    return return_data\n",
    "    \n",
    "    \n",
    "def geo_retrieving(data):\n",
    "    return_data={}\n",
    "    if data['place'] != None:\n",
    "        return_data['tweet_geo_id'] = data['id']\n",
    "        return_data['full_name'] = data['place']['full_name']\n",
    "        return_data['country'] = data['place']['country']\n",
    "        return_data['country_code'] = data['place']['country_code']\n",
    "        return return_data\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def user_retrieving(data):\n",
    "    keys = data.keys()\n",
    "    user_data = {}\n",
    "    if 'user' in keys:\n",
    "        user_data['user_id'] = data['user']['id']\n",
    "        user_data['name'] = data['user']['name']\n",
    "        user_data['screen_name'] = data['user']['screen_name']\n",
    "        user_data['location'] = data['user']['location']\n",
    "        user_data['followers_count'] = data['user']['followers_count']\n",
    "        user_data['friends_count'] = data['user']['friends_count']\n",
    "    return user_data\n",
    "\n",
    "def parse_data(data, cursor):\n",
    "    for n,line in enumerate(data):\n",
    "        tweet_data, entities, geo_data, special = tweet_classification(line)\n",
    "        \n",
    "        if tweet_data == 'delete':\n",
    "            continue\n",
    "        insert('tweets', tweet_data, cursor)\n",
    "        if geo_data != None:\n",
    "            geo_data['tweet_type'] = tweet_data['tweet_type']\n",
    "            insert('tweets_geo', geo_data, cursor)\n",
    "            \n",
    "        if tweet_data['tweet_type'] == 'retweet':\n",
    "            insert('retweets', special, cursor)\n",
    "        if tweet_data['tweet_type'] == 'reply':\n",
    "            insert('replies', special, cursor)\n",
    "        if tweet_data['tweet_type'] == 'quote':\n",
    "            insert('quotes', special, cursor)\n",
    "        insert('users', user_retrieving(line), cursor)\n",
    "        \n",
    "        for a_hashtag in entities['hashtags']:\n",
    "            hashtag={}\n",
    "            hashtag['tweet_id'] = tweet_data['tweet_id']\n",
    "            hashtag['text'] = a_hashtag\n",
    "            insert('hashtags', hashtag, cursor)\n",
    "        for a_symbol in entities['symbols']:\n",
    "            symbol={}\n",
    "            symbol['tweet_id'] = tweet_data['tweet_id']\n",
    "            symbol['text'] = a_symbol\n",
    "            insert('symbols', symbol, cursor)\n",
    "        for a_user_mention in entities['user_mentions']:\n",
    "            user_mention={}\n",
    "            user_mention['tweet_id'] = tweet_data['tweet_id']\n",
    "            user_mention['text'] = a_user_mention\n",
    "            insert('user_mentions', user_mention, cursor)\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "def create_all_tables(db_file):\n",
    "    create_tweets_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tweets(\n",
    "        tweet_id INTEGER PRIMARY KEY,\n",
    "        user_id INTEGER NOT NULL,\n",
    "        timestamp_ms INTEGER NOT NULL, \n",
    "        text TEXT NOT NULL,\n",
    "        lang TEXT NOT NULL,\n",
    "        tweet_type TEXT NOT NULL,\n",
    "        FOREIGN KEY (user_id) REFERENCES users(user_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_replies_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS replies(\n",
    "        reply_id INTEGER PRIMARY KEY,\n",
    "        reply_to_status_id INTEGER NOT NULL,\n",
    "        reply_to_user_id INTEGER NOT NULL,\n",
    "        FOREIGN KEY (reply_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_retweets_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS retweets(\n",
    "        retweet_id INTEGER PRIMARY KEY,\n",
    "        retweet_of_status_id INTEGER NOT NULL,\n",
    "        FOREIGN KEY (retweet_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_quotes_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS quotes(\n",
    "        quote_id INTEGER PRIMARY KEY,\n",
    "        quote_of_status_id INTEGER NOT NULL,\n",
    "        FOREIGN KEY (quote_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_users_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users(\n",
    "        user_id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        screen_name TEXT NOT NULL,\n",
    "        location TEXT,\n",
    "        followers_count INTEGER NOT NULL,\n",
    "        friends_count INTEGER NOT NULL\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_hashtags_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hashtags(\n",
    "        hashtag_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        tweet_id INTEGER NOT NULL,\n",
    "        text TEXT NOT NULL,\n",
    "        FOREIGN KEY (tweet_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "    create_user_mentions_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_mentions(\n",
    "        user_mention_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        tweet_id INTEGER NOT NULL,\n",
    "        text TEXT NOT NULL,\n",
    "        FOREIGN KEY (tweet_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "    create_symbols_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS symbols(\n",
    "        symbol_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        tweet_id INTEGER NOT NULL,\n",
    "        text TEXT NOT NULL,\n",
    "        FOREIGN KEY (tweet_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    create_tweets_geo_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tweets_geo(\n",
    "        tweet_geo_id INTEGER NOT NULL PRIMARY KEY,\n",
    "        full_name TEXT NOT NULL, \n",
    "        country TEXT NOT NULL,\n",
    "        country_code TEXT NOT NULL,\n",
    "        tweet_type TEXT NOT NULL,\n",
    "        FOREIGN KEY (tweet_geo_id) REFERENCES tweets(tweet_id)\n",
    "    );\n",
    "    \"\"\"    \n",
    "    conn = create_connection(db_file)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(create_users_table)\n",
    "    cursor.execute(create_tweets_table)\n",
    "    cursor.execute(create_tweets_geo_table)\n",
    "    cursor.execute(create_replies_table)\n",
    "    cursor.execute(create_retweets_table)\n",
    "    cursor.execute(create_quotes_table)\n",
    "    cursor.execute(create_hashtags_table)\n",
    "    cursor.execute(create_symbols_table)\n",
    "    cursor.execute(create_user_mentions_table)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d935e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_connection(db_name)\n",
    "create_all_tables(db_name)\n",
    "go_through_files(directory_with_files, db_name) # go through files "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
